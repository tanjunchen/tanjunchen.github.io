<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>大模型 on 漫步远方，心荡神往</title><link>https://tanjunchen.github.io/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/</link><description>Recent content in 大模型 on 漫步远方，心荡神往</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>陈谭军</copyright><lastBuildDate>Sat, 08 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://tanjunchen.github.io/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/index.xml" rel="self" type="application/rss+xml"/><item><title>LLM 教程（2）- 大模型基础知识</title><link>https://tanjunchen.github.io/post/2025-03-08-llm-learn2/</link><pubDate>Sat, 08 Mar 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-03-08-llm-learn2/</guid><description>LLM 专有名词 量化（Quantization） 基础知识 LLM 大模型的量化技术主要是通过对模型参数进行压缩和量化，从而降低模型的存储和计算复杂度。具体</description></item><item><title>LLM 教程（1）- DeepSeek-R1 初步入门</title><link>https://tanjunchen.github.io/post/2025-03-01-llm-learn1/</link><pubDate>Sat, 01 Mar 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-03-01-llm-learn1/</guid><description>基础知识 查看 deepseek-ai 开源官网，DeepSeek 有以下系列： DeepSeek-R1 DeepSeek-V3 （DeepSeek-V3-Base） DeepSeek-VL DeepSeek-Coder DeepSeek-Math DeepSeek-LLM 蒸馏模型系列（Qwen、LLaMA等） &amp;hellip;&amp;hellip;</description></item><item><title>A800 单机8卡体验 DeepSeek-R1-AWQ 量化满血版之旅</title><link>https://tanjunchen.github.io/post/2025-02-23-a800-deepseek-awq/</link><pubDate>Sun, 23 Feb 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-02-23-a800-deepseek-awq/</guid><description>硬件与系统环境要求 硬件配置 GPU: 8× NVIDIA A800 80GB 显存要求: 每卡80GB 系统内存: ≥32GB (用于交换空间) CPU：lscpu | grep &amp;ldquo;Model name&amp;rdquo; 值：Model name: Intel(R)</description></item><item><title>A800 单机8卡体验 DeepSeek-R1-AWQ 量化满血版之旅</title><link>https://tanjunchen.github.io/post/2025-03-09-llm-deepseek-r1/</link><pubDate>Sun, 23 Feb 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-03-09-llm-deepseek-r1/</guid><description/></item><item><title>vLLM 多机多卡推理测试与验证（Docker）</title><link>https://tanjunchen.github.io/post/2025-01-19-inference-serve/</link><pubDate>Sun, 19 Jan 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-01-19-inference-serve/</guid><description>基础概念 【分布式推理与服务】（Distributed Inference and Serving）是指在多个机器或设备之间部署和管理机器学习模型，以高效地处理推理请求</description></item><item><title>vLLM 多机多卡推理测试与验证（Kubernetes）</title><link>https://tanjunchen.github.io/post/2025-01-19-inference-serve-k8s/</link><pubDate>Sun, 19 Jan 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-01-19-inference-serve-k8s/</guid><description>基础概念 【分布式推理与服务】（Distributed Inference and Serving）是指在多个机器或设备之间部署和管理机器学习模型，以高效地处理推理请求</description></item><item><title>云原生 AI 能力引擎（大模型 AI 基础套件）</title><link>https://tanjunchen.github.io/post/2025-01-05-ai-infra/</link><pubDate>Sun, 05 Jan 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-01-05-ai-infra/</guid><description>本文详尽列举了构建和实施先进人工智能（AI）解决方案所需的关键技术组件。 首先，针对单机环境，文档罗列了并行计算平台、GPU驱动程序、容器化工</description></item></channel></rss>