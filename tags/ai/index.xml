<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI on 漫步远方，心荡神往</title><link>https://tanjunchen.github.io/tags/ai/</link><description>Recent content in AI on 漫步远方，心荡神往</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>陈谭军</copyright><lastBuildDate>Sat, 01 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://tanjunchen.github.io/tags/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>LLM 教程（1）- DeepSeek-R1 初步入门</title><link>https://tanjunchen.github.io/post/2025-03-01-llm-learn1/</link><pubDate>Sat, 01 Mar 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-03-01-llm-learn1/</guid><description>基础知识 查看 deepseek-ai 开源官网，DeepSeek 有以下系列： DeepSeek-R1 DeepSeek-V3 （DeepSeek-V3-Base） DeepSeek-VL DeepSeek-Coder DeepSeek-Math DeepSeek-LLM 蒸馏模型系列（Qwen、LLaMA等） &amp;hellip;&amp;hellip;</description></item><item><title>A800 单机8卡体验 DeepSeek-R1-AWQ 量化满血版之旅</title><link>https://tanjunchen.github.io/post/2025-02-23-a800-deepseek-awq/</link><pubDate>Sun, 23 Feb 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-02-23-a800-deepseek-awq/</guid><description>硬件与系统环境要求 硬件配置 GPU: 8× NVIDIA A800 80GB 显存要求: 每卡80GB 系统内存: ≥32GB (用于交换空间) CPU：lscpu | grep &amp;ldquo;Model name&amp;rdquo; 值：Model name: Intel(R)</description></item><item><title>A800 单机8卡体验 DeepSeek-R1-AWQ 量化满血版之旅</title><link>https://tanjunchen.github.io/post/2025-03-08-llm-learn2/</link><pubDate>Sun, 23 Feb 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-03-08-llm-learn2/</guid><description/></item><item><title>A800 单机8卡体验 DeepSeek-R1-AWQ 量化满血版之旅</title><link>https://tanjunchen.github.io/post/2025-03-09-llm-deepseek-r1/</link><pubDate>Sun, 23 Feb 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-03-09-llm-deepseek-r1/</guid><description/></item><item><title>vLLM 多机多卡推理测试与验证（Docker）</title><link>https://tanjunchen.github.io/post/2025-01-19-inference-serve/</link><pubDate>Sun, 19 Jan 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-01-19-inference-serve/</guid><description>基础概念 【分布式推理与服务】（Distributed Inference and Serving）是指在多个机器或设备之间部署和管理机器学习模型，以高效地处理推理请求</description></item><item><title>vLLM 多机多卡推理测试与验证（Kubernetes）</title><link>https://tanjunchen.github.io/post/2025-01-19-inference-serve-k8s/</link><pubDate>Sun, 19 Jan 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-01-19-inference-serve-k8s/</guid><description>基础概念 【分布式推理与服务】（Distributed Inference and Serving）是指在多个机器或设备之间部署和管理机器学习模型，以高效地处理推理请求</description></item><item><title>云原生 AI 能力引擎（大模型 AI 基础套件）</title><link>https://tanjunchen.github.io/post/2025-01-05-ai-infra/</link><pubDate>Sun, 05 Jan 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-01-05-ai-infra/</guid><description>本文详尽列举了构建和实施先进人工智能（AI）解决方案所需的关键技术组件。 首先，针对单机环境，文档罗列了并行计算平台、GPU驱动程序、容器化工</description></item><item><title>2025 新年快乐（Happy New Year）</title><link>https://tanjunchen.github.io/post/2025-01-01-happy-new-year/</link><pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-01-01-happy-new-year/</guid><description>新年的钟声已经敲响，我们迎来了崭新的 2025年！🎉 感谢过去一年里大家的陪伴与支持，新的一年，愿我们一起迎接更多美好的时刻。🌟 祝愿大家在 2025 年 ✨</description></item></channel></rss>