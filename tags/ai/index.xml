<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI on 漫步远方，心荡神往</title><link>https://tanjunchen.github.io/tags/ai/</link><description>Recent content in AI on 漫步远方，心荡神往</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>陈谭军</copyright><lastBuildDate>Sun, 01 Jun 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://tanjunchen.github.io/tags/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>探索 Transformer 理论与本质</title><link>https://tanjunchen.github.io/post/2025-06-01-transformer-01/</link><pubDate>Sun, 01 Jun 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-06-01-transformer-01/</guid><description>1. 语言模型训练和推理 一般来说，语言模型旨在对于人类语言的内在规律进行建模，从而准确预测词序列中未来（或缺失）词或词元（Token）的概率。根</description></item><item><title>科普开源大模型基础知识</title><link>https://tanjunchen.github.io/post/2025-05-07-llm-01/</link><pubDate>Wed, 07 May 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-05-07-llm-01/</guid><description>Llama 4 北京时间2025年4月6日凌晨，Meta发布了外界期待许久的Llama4系列开源模型，目前它包括 Llama 4 Scout、Llama 4 Maveri</description></item><item><title>DeepSeek 开源周活动</title><link>https://tanjunchen.github.io/post/2025-05-01-deepseek-weekly/</link><pubDate>Thu, 01 May 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-05-01-deepseek-weekly/</guid><description>1. DeepSeek 开源周 DeepSeek 在开源了 DeepSeek-R1 与 DeepSeek-V3 模型权重后，DeepSeek-V3 技术报告 《DeepSeek-V3 Technical Report》 中提到的很多核心技术，相继在 &amp;ldquo;DeepSeek 开</description></item><item><title>双机2*H20(8*96GiB)部署满血DeepSeek-R1(fp8)验证过程</title><link>https://tanjunchen.github.io/post/2025-04-05-2h20-deepseek-r1-sglang-vllm/</link><pubDate>Sat, 05 Apr 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-04-05-2h20-deepseek-r1-sglang-vllm/</guid><description>环境信息 机器配置 OS：CentOS Linux release 7.6 (Final) Kernel：4.19.0-1.0.0.9 驱动： Driver Version: 535.216.03 CUDA Version: 12.2 GPU：NVIDIA H20 vLLM：htt</description></item><item><title>单机H20(8*96GiB)部署满血DeepSeek-R1(fp8)验证过程</title><link>https://tanjunchen.github.io/post/2025-04-04-h20-deepseek-r1-sglang-vllm/</link><pubDate>Fri, 04 Apr 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-04-04-h20-deepseek-r1-sglang-vllm/</guid><description>环境信息 机器配置 OS：CentOS Linux release 7.6 (Final) Kernel：4.19.0-1.0.0.9 驱动： Driver Version: 535.216.03 CUDA Version: 12.2 GPU：NVIDIA H20 vLLM：htt</description></item><item><title>单台 H20 机器 DeepSeek R1 (FP8)、DeepSeek-R1-Block-INT8 精度测试与性能测试过程</title><link>https://tanjunchen.github.io/post/2025-03-23-h20-deepseek-r1/</link><pubDate>Sun, 23 Mar 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-03-23-h20-deepseek-r1/</guid><description>测试目标 测试下 DeepSeek R1（FP8） 使用单台 H20 机器在 aime、math500、gpqa (使用开源工具 evalscope) 数据集下进行精度测试； 给定输入、输出等参数，</description></item><item><title>DeepSeek R1 推理 GPU 资源配置</title><link>https://tanjunchen.github.io/post/2025-03-15-deepseek-r1-gpu-resource/</link><pubDate>Sat, 15 Mar 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-03-15-deepseek-r1-gpu-resource/</guid><description>Deepseek R1 推理资源需求 量化与 FP8 动态转换： 暂不考虑量化技术； FP8 动态转换因性能损失较大，不推荐使用。因此，默认情况下，不具备 FP8 计算单元的显卡无法运行 FP8</description></item><item><title>LLM 教程（3）- 《DeepSeek R1 论文精读 - 通过强化学习推动大语言模型推理能力的突破与创新》</title><link>https://tanjunchen.github.io/post/2025-03-09-llm-deepseek-r1/</link><pubDate>Sun, 09 Mar 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-03-09-llm-deepseek-r1/</guid><description>1. 序言 下图展示了 OpenAI（公开文献） 从预训练开始逐步训练出一个 GPT 助手的步骤；pre-training -&amp;gt; SFT -&amp;gt; RM -&amp;gt; RL 是典型的大模型训练过程。</description></item><item><title>LLM 教程（2）- 大模型基础知识</title><link>https://tanjunchen.github.io/post/2025-03-08-llm-learn2/</link><pubDate>Sat, 08 Mar 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-03-08-llm-learn2/</guid><description>LLM 专有名词 量化（Quantization） 基础知识 LLM 大模型的量化技术主要是通过对模型参数进行压缩和量化，从而降低模型的存储和计算复杂度。具体</description></item><item><title>LLM 教程（1）- DeepSeek-R1 初步入门</title><link>https://tanjunchen.github.io/post/2025-03-01-llm-learn1/</link><pubDate>Sat, 01 Mar 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-03-01-llm-learn1/</guid><description>基础知识 查看 deepseek-ai 开源官网，DeepSeek 有以下系列： DeepSeek-R1 DeepSeek-V3 （DeepSeek-V3-Base） DeepSeek-VL DeepSeek-Coder DeepSeek-Math DeepSeek-LLM 蒸馏模型系列（Qwen、LLaMA等） &amp;hellip;&amp;hellip;</description></item><item><title>A800 单机8卡体验 DeepSeek-R1-AWQ 量化满血版之旅</title><link>https://tanjunchen.github.io/post/2025-02-23-a800-deepseek-awq/</link><pubDate>Sun, 23 Feb 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-02-23-a800-deepseek-awq/</guid><description>硬件与系统环境要求 硬件配置 GPU: 8× NVIDIA A800 80GB 显存要求: 每卡80GB 系统内存: ≥32GB (用于交换空间) CPU：lscpu | grep &amp;ldquo;Model name&amp;rdquo; 值：Model name: Intel(R)</description></item><item><title>vLLM 多机多卡推理测试与验证（Docker）</title><link>https://tanjunchen.github.io/post/2025-01-19-inference-serve/</link><pubDate>Sun, 19 Jan 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-01-19-inference-serve/</guid><description>基础概念 【分布式推理与服务】（Distributed Inference and Serving）是指在多个机器或设备之间部署和管理机器学习模型，以高效地处理推理请求</description></item><item><title>vLLM 多机多卡推理测试与验证（Kubernetes）</title><link>https://tanjunchen.github.io/post/2025-01-19-inference-serve-k8s/</link><pubDate>Sun, 19 Jan 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-01-19-inference-serve-k8s/</guid><description>基础概念 【分布式推理与服务】（Distributed Inference and Serving）是指在多个机器或设备之间部署和管理机器学习模型，以高效地处理推理请求</description></item><item><title>云原生 AI 能力引擎（大模型 AI 基础套件）</title><link>https://tanjunchen.github.io/post/2025-01-05-ai-infra/</link><pubDate>Sun, 05 Jan 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-01-05-ai-infra/</guid><description>本文详尽列举了构建和实施先进人工智能（AI）解决方案所需的关键技术组件。 首先，针对单机环境，文档罗列了并行计算平台、GPU驱动程序、容器化工</description></item><item><title>2025 新年快乐（Happy New Year）</title><link>https://tanjunchen.github.io/post/2025-01-01-happy-new-year/</link><pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate><guid>https://tanjunchen.github.io/post/2025-01-01-happy-new-year/</guid><description>新年的钟声已经敲响，我们迎来了崭新的 2025年！🎉 感谢过去一年里大家的陪伴与支持，新的一年，愿我们一起迎接更多美好的时刻。🌟 祝愿大家在 2025 年 ✨</description></item></channel></rss>