<!doctype html><html lang=en-us><head><meta name=generator content="Hugo 0.101.0"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:site_name" content="漫步远方，心荡神往"><meta property="og:type" content="article"><meta property="og:image" content="https://tanjunchen.github.io/img/home.webp"><meta property="twitter:image" content="https://tanjunchen.github.io/img/home.webp"><meta name=title content><meta property="og:title" content><meta property="twitter:title" content><meta name=description content="陈谭军，软件工程师, 开源爱好者, 互联网, 云原生, 容器, 微服务, Web, PaaS, Istio, Kubernetes, Microservice"><meta property="og:description" content="陈谭军，软件工程师, 开源爱好者, 互联网, 云原生, 容器, 微服务, Web, PaaS, Istio, Kubernetes, Microservice"><meta property="twitter:description" content="陈谭军，软件工程师, 开源爱好者, 互联网, 云原生, 容器, 微服务, Web, PaaS, Istio, Kubernetes, Microservice"><meta property="twitter:card" content="summary"><meta name=keyword content="陈谭军, 互联网, 云原生, 容器, 微服务, Web, PaaS, Istio, Kubernetes, Microservice"><link rel="shortcut icon" href=/img/favicon.ico><title>漫步远方，心荡神往 | 陈谭军的博客 | tanjunchen Blog</title><link rel=canonical href=/><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/hugo-theme-cleanwhite.min.css><link rel=stylesheet href=/css/zanshang.css><link rel=stylesheet href=/css/font-awesome.all.min.css><script src=/js/jquery.min.js></script>
<script src=/js/bootstrap.min.js></script>
<script src=/js/hux-blog.min.js></script>
<script src=/js/lazysizes.min.js></script></head><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class=container-fluid><div class="navbar-header page-scroll"><button type=button class=navbar-toggle>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span></button>
<a class=navbar-brand href=/>漫步远方，心荡神往</a></div><div id=huxblog_navbar><div class=navbar-collapse><ul class="nav navbar-nav navbar-right"><li><a href=/>All Posts</a></li><li><a href=/categories/technology/>technology</a></li><li><a href=/categories/think/>think</a></li><li><a href=/learning/>LEARNING</a></li><li><a href=/archive/>ARCHIVE</a></li><li><a href=/about/>ABOUT</a></li><li><a href=/search><i class="fa fa-search"></i></a></li></ul></div></div></div></nav><script>var $body=document.body,$toggle=document.querySelector(".navbar-toggle"),$navbar=document.querySelector("#huxblog_navbar"),$collapse=document.querySelector(".navbar-collapse");$toggle.addEventListener("click",handleMagic);function handleMagic(){$navbar.className.indexOf("in")>0?($navbar.className=" ",setTimeout(function(){$navbar.className.indexOf("in")<0&&($collapse.style.height="0px")},400)):($collapse.style.height="auto",$navbar.className+=" in")}</script><header class=intro-header style=background-image:url(/img/home.webp)><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=site-heading><h1>漫步远方，心荡神往</h1><span class=subheading></span></div></div></div></div></header><div data-pagefind-ignore=all class=container><div class=row><div class="col-lg-8 col-lg-offset-1
col-md-8 col-md-offset-1
col-sm-12
col-xs-12
post-container"><div data-pagefind-ignore=all><div class=post-preview><a href=https://tanjunchen.github.io/post/2025-02-23-a800-deepseek-awq/><h2 class=post-title>A800 单机8卡体验 DeepSeek-R1-AWQ 量化满血版之旅</h2><h3 class=post-subtitle>A800 单机8卡体验 DeepSeek-R1-AWQ 量化满血版之旅</h3><div class=post-content-preview>硬件与系统环境要求 硬件配置 GPU: 8× NVIDIA A800 80GB 显存要求: 每卡80GB 系统内存: ≥32GB (用于交换空间) CPU：lscpu | grep &ldquo;Model name&rdquo; 值：Model name: Intel(R)</div></a><p class=post-meta>Posted by 陈谭军 on Sunday, February 23, 2025</p></div><hr><div class=post-preview><a href=https://tanjunchen.github.io/post/2025-01-19-inference-serve/><h2 class=post-title>vLLM 多机多卡推理测试与验证（Docker）</h2><h3 class=post-subtitle>vLLM 多机多卡推理 docker 验证</h3><div class=post-content-preview>vLLM 采用多机多卡推理，是为了解决超大规模模型的显存限制、算力瓶颈、高并发吞吐需求以及长序列处理等挑战。通过模型并行、数据并行和高效的内存管理技术，vLLM 能将模型参数和计算任务分布到多块 GPU 和多台机器上，充分利用硬件资源，实现快速、高效的推理能力，满足工业级场景中对性能和扩展性的要求。</div></a><p class=post-meta>Posted by 陈谭军 on Sunday, January 19, 2025</p></div><hr><div class=post-preview><a href=https://tanjunchen.github.io/post/2025-01-19-inference-serve-k8s/><h2 class=post-title>vLLM 多机多卡推理测试与验证（Kubernetes）</h2><h3 class=post-subtitle>vLLM 多机多卡推理 Kubernetes 验证</h3><div class=post-content-preview>vLLM 采用多机多卡推理，是为了解决超大规模模型的显存限制、算力瓶颈、高并发吞吐需求以及长序列处理等挑战。通过模型并行、数据并行和高效的内存管理技术，vLLM 能将模型参数和计算任务分布到多块 GPU 和多台机器上，充分利用硬件资源，实现快速、高效的推理能力，满足工业级场景中对性能和扩展性的要求。</div></a><p class=post-meta>Posted by 陈谭军 on Sunday, January 19, 2025</p></div><hr><div class=post-preview><a href=https://tanjunchen.github.io/post/2025-01-05-ai-infra/><h2 class=post-title>云原生 AI 能力引擎（大模型 AI 基础套件）</h2><h3 class=post-subtitle>本文详尽列举了构建和实施先进人工智能（AI）解决方案所需的关键技术组件。</h3><div class=post-content-preview>本内容概述了现代计算与人工智能生态系统的关键领域，包括单机环境配置（如 CUDA、GPU 驱动）、容器与 Kubernetes 的支持（如容器运行时、设备插件）、硬件与计算管理（GPU 虚拟化、调度器）、网络与存储方案、AI 框架（深度学习、机器学习、分布式训练、自动化工具）、可观测性与故障诊断（日志、监控、链路追踪、诊断工具）、开源大模型（NLP、多模态模型）、训练与推理框架，以及国产化解决方案（国产硬件与 AI 框架）。</div></a><p class=post-meta>Posted by 陈谭军 on Sunday, January 5, 2025</p></div><hr><div class=post-preview><a href=https://tanjunchen.github.io/post/2025-01-01-happy-new-year/><h2 class=post-title>2025 新年快乐（Happy New Year）</h2><div class=post-content-preview>新年的钟声已经敲响，我们迎来了崭新的 2025年！🎉 感谢过去一年里大家的陪伴与支持，新的一年，愿我们一起迎接更多美好的时刻。🌟 祝愿大家在 2025 年 ✨</div></a><p class=post-meta>Posted by 陈谭军 on Wednesday, January 1, 2025</p></div><hr></div><ul class=pager data-pagefind-ignore=all><li class=next><a href=/page/2/>Older Posts &rarr;</a></li></ul></div><div class="col-lg-3 col-lg-offset-0
col-md-3 col-md-offset-0
col-sm-12
col-xs-12
sidebar-container"><section class="visible-md visible-lg"><div class=short-about><a href=/about><img src=/img/tanjunchen.jpg alt=avatar style=cursor:pointer></a><p>Software Developer</p><ul class=list-inline><li><a href=mailto:tanjunchen20@gmail.com><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i>
<i class="fa fa-envelope fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=/img/wechat.jpg><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-weixin fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://github.com/tanjunchen><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-github fa-stack-1x fa-inverse"></i></span></a></li></ul></div></section></div></div></div><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"><li><a href=mailto:tanjunchen20@gmail.com><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-envelope fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=/img/wechat.jpg><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-weixin fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://github.com/tanjunchen><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-github fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="copyright text-muted">Copyright &copy; 陈谭军 2025</p></div></div></div></footer><script>function loadAsync(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(null,e)},!1),i.parentNode.insertBefore(n,i)}</script><script>$("#tag_cloud").length!==0&&loadAsync("/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:"#bbbbee",end:"#0085a1"}},$("#tag_cloud a").tagcloud()})</script><script>loadAsync("https://cdn.jsdelivr.net/npm/fastclick@1.0.6/lib/fastclick.min.js",function(){var e=document.querySelector("nav");e&&FastClick.attach(e)})</script><script type=text/javascript>function generateCatalog(e){_containerSelector="div.post-container";var t,n,s,o,i,r=$(_containerSelector),a=r.find("h1,h2,h3,h4,h5,h6");return $(e).html(""),a.each(function(){n=$(this).prop("tagName").toLowerCase(),i="#"+$(this).prop("id"),s=$(this).text(),t=$('<a href="'+i+'" rel="nofollow">'+s+"</a>"),o=$('<li class="'+n+'_nav"></li>').append(t),$(e).append(o)}),!0}generateCatalog(".catalog-body"),$(".catalog-toggle").click(function(e){e.preventDefault(),$(".side-catalog").toggleClass("fold")}),loadAsync("/js/jquery.nav.js",function(){$(".catalog-body").onePageNav({currentClass:"active",changeHash:!1,easing:"swing",filter:"",scrollSpeed:700,scrollOffset:0,scrollThreshold:.2,begin:null,end:null,scrollChange:null,padding:80})})</script></body></html>