<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:site_name" content="漫步远方，心荡神往"><meta property="og:type" content="article"><meta property="og:image" content="https://tanjunchen.github.io/img/home.webp"><meta property="twitter:image" content="https://tanjunchen.github.io/img/home.webp"><meta name=title content="DeepSeek R1 推理 GPU 资源配置"><meta property="og:title" content="DeepSeek R1 推理 GPU 资源配置"><meta property="twitter:title" content="DeepSeek R1 推理 GPU 资源配置"><meta name=description content="介绍 NVIDIA 基础知识，如硬件类型/厂家、NVIDIA 显卡系列、SXM 与 PCIe、DeepSeek R1 资源需求示例"><meta property="og:description" content="介绍 NVIDIA 基础知识，如硬件类型/厂家、NVIDIA 显卡系列、SXM 与 PCIe、DeepSeek R1 资源需求示例"><meta property="twitter:description" content="介绍 NVIDIA 基础知识，如硬件类型/厂家、NVIDIA 显卡系列、SXM 与 PCIe、DeepSeek R1 资源需求示例"><meta property="twitter:card" content="summary"><meta name=keyword content="陈谭军, 互联网, 云原生, 容器, 微服务, Web, PaaS, Istio, Kubernetes, Microservice"><link rel="shortcut icon" href=/img/favicon.ico><title>DeepSeek R1 推理 GPU 资源配置 | 陈谭军的博客 | tanjunchen Blog</title><link rel=canonical href=/post/2025-03-15-deepseek-r1-gpu-resource/><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/hugo-theme-cleanwhite.min.css><link rel=stylesheet href=/css/zanshang.css><link rel=stylesheet href=/css/font-awesome.all.min.css><script src=/js/jquery.min.js></script>
<script src=/js/bootstrap.min.js></script>
<script src=/js/hux-blog.min.js></script>
<script src=/js/lazysizes.min.js></script></head><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class=container-fluid><div class="navbar-header page-scroll"><button type=button class=navbar-toggle>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span></button>
<a class=navbar-brand href=/>漫步远方，心荡神往</a></div><div id=huxblog_navbar><div class=navbar-collapse><ul class="nav navbar-nav navbar-right"><li><a href=/>All Posts</a></li><li><a href=/categories/technology/>technology</a></li><li><a href=/categories/think/>think</a></li><li><a href=/learning/>LEARNING</a></li><li><a href=/archive/>ARCHIVE</a></li><li><a href=/about/>ABOUT</a></li><li><a href=/search><i class="fa fa-search"></i></a></li></ul></div></div></div></nav><script>var $body=document.body,$toggle=document.querySelector(".navbar-toggle"),$navbar=document.querySelector("#huxblog_navbar"),$collapse=document.querySelector(".navbar-collapse");$toggle.addEventListener("click",handleMagic);function handleMagic(){$navbar.className.indexOf("in")>0?($navbar.className=" ",setTimeout(function(){$navbar.className.indexOf("in")<0&&($collapse.style.height="0px")},400)):($collapse.style.height="auto",$navbar.className+=" in")}</script><style type=text/css>header.intro-header{background-image:url(/img/home.webp)}</style><header class=intro-header><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><div class=tags><a class=tag href=/tags/ai title=AI>AI</a>
<a class=tag href=/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B title=大模型>大模型</a>
<a class=tag href=/tags/deepseek title=DeepSeek>DeepSeek</a></div><h1>DeepSeek R1 推理 GPU 资源配置</h1><h2 class=subheading>普及 NVIDIA 基础知识，如硬件类型/厂家、NVIDIA 显卡系列、SXM 与 PCIe、DeepSeek R1 资源需求示例</h2><span class=meta>Posted by
陈谭军
on
Saturday, March 15, 2025
<span id=busuanzi_container_page_pv>|<span id=busuanzi_value_page_pv></span><span>
<span id=/post/2025-03-15-deepseek-r1-gpu-resource/ class="leancloud_visitors meta_data_item" data-flag-title><span class=post-meta-item-icon><span class="octicon octicon-eye"></span></span>
<i class="fa fa-eye"></i>
<span class=old-visitors-count style=display:none></span>
<span class=leancloud-visitors-count></span></span>
<script src=https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js></script>
<script>AV.initialize("","")</script><script type=text/javascript>function showTime(e){var n=new AV.Query(e),t=[],s=$(".leancloud_visitors");s.each(function(){t.push($(this).attr("id").trim())}),n.containedIn("url",t),n.find().done(function(e){for(var s,o,i,a,r,c,l=".leancloud-visitors-count",d=".old-visitors-count",n=0;n<e.length;n++)a=e[n],i=a.get("url"),c=a.get("time"),s=document.getElementById(i),$(s).find(l).text(c);for(n=0;n<t.length;n++)i=t[n],s=document.getElementById(i),o=$(s).find(l),o.text()==""&&(r=$(s).find(d).text(),r!=""?o.text(0+parseInt(r)):o.text(0))}).fail(function(e,t){console.log("Error: "+t.code+" "+t.message)})}function addCount(e){var n=$(".leancloud_visitors"),t=n.attr("id").trim(),o=n.attr("data-flag-title").trim(),s=new AV.Query(e);s.equalTo("url",t),s.find({success:function(n){if(n.length>0){var s,i,r,c,l,a=n[0];a.fetchWhenSave(!0),a.increment("time"),a.save(null,{success:function(e){var n=$(document.getElementById(t));n.find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to save Visitor num, with error message: "+t.message)}})}else s=new e,i=new AV.ACL,i.setPublicReadAccess(!0),i.setPublicWriteAccess(!0),s.setACL(i),s.set("title",o),s.set("url",t),c=".old-visitors-count",l=$(document.getElementById(t)),r=l.find(c).text(),r!=""?s.set("time",parseInt(r)+1):s.set("time",1),s.save(null,{success:function(e){var n=$(document.getElementById(t));n.find(".leancloud-visitors-count").text(e.get("time"))},error:function(){console.log("Failed to create")}})},error:function(e){console.log("Error:"+e.code+" "+e.message)}})}$(function(){var e=AV.Object.extend("Counter");$(".leancloud_visitors").length==1?addCount(e):showTime(e)})</script>阅读 </span></span>|<span class=post-date>共 2393 字</span>，阅读约 <span class=more-meta>5 分钟</span></span></div></div></div></div></header><article><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
post-container"><h1 id=deepseek-r1-推理资源需求>Deepseek R1 推理资源需求</h1><ul><li>量化与 FP8 动态转换：<ul><li>暂不考虑量化技术；</li><li>FP8 动态转换因性能损失较大，不推荐使用。因此，默认情况下，不具备 FP8 计算单元的显卡无法运行 FP8 模型。</li></ul></li><li>Deepseek 模型显存需求：<ul><li>Deepseek 是原生 FP8 模型，其显存占用约等于参数量（671B 参数约占用 700GB 显存），无需额外乘 2。但运行该模型需要推理设备具备 FP8 计算单元。</li><li>除模型本身外，还需预留上下文和并发所需的 KV Cache，约 200-300GB。并发需求的 KV Cache 无上限。</li><li>对于具备 FP8 计算单元的设备，显存需求至少为 1TB；对于仅支持 BF16 的设备（如 A100），模型显存占用将翻倍至 1.4TB，上下文显存需求同样增加，总显存需求约 1.6TB 以上。因此，A100 不推荐用于 Deepseek 推理。</li></ul></li><li>硬件性能与互联需求：<ul><li>模型推理对卡间互联带宽要求较低，Fine-tune 阶段亦如此，仅训练阶段对带宽有较高需求。</li><li>GB200 未列入推荐方案，主要因其价格昂贵、货源稀缺且散热设计存在潜在问题。</li></ul></li><li>硬件迭代与趋势：<ul><li>显卡迭代速度较快，A100 因缺乏 FP8 计算单元，在 Deepseek 推理场景中已显落后。<span style=color:red>Blackwell 架构引入原生 FP4 计算单元，若未来出现强开源 FP4 模型，H100/H200 亦可能面临淘汰。</span></li><li>模型推理仅依赖特定计算单元，未来可能出现专为推理设计的硬件。</li></ul></li><li>配置与成本：<ul><li>所列配置仅能满足基本运行需求，并发性能支持数十人规模，更大规模需进一步扩展硬件配置。</li></ul></li></ul><p><span style=color:red>总体而言，Deepseek 推理对硬件要求较高，需投入较大成本，适合具备实力的机构或企业部署。</span></p><p>下面，给大家普及 NVIDIA 基础知识，如硬件类型/厂家、NVIDIA 显卡系列、SXM 与 PCIe、DeepSeek R1 资源需求示例等；</p><h1 id=硬件类型厂家>硬件类型/厂家</h1><table><thead><tr><th>系列</th><th>纯 CPU 推理</th><th>Nvidia 显卡</th><th>AMD 显卡</th><th>华为显卡</th></tr></thead><tbody><tr><td>优点</td><td>成本最低</td><td>性能最好，而且结果可预测</td><td>价格比 Nvidia 平台稍低，性能良好，官方表明支持 Deepseek 推理</td><td>硅基流动说他家用华为的卡做的推理，感觉工具链应该是能跑起来</td></tr><tr><td>缺点</td><td>速度太慢，而且并发性能衰减大</td><td>价格高</td><td>AMD 驱动等各种工具链还在频繁更新优化性能</td><td>资料少，很难获得支持，可能要折腾</td></tr></tbody></table><h1 id=nvidia-显卡系列>NVIDIA 显卡系列</h1><table><thead><tr><th>系列</th><th>Pascal</th><th>Volta</th><th>Turing</th><th>Ampere</th><th>Ada</th><th>Hopper</th><th>Blackwell</th></tr></thead><tbody><tr><td>发布时间</td><td>2016</td><td>2017</td><td>2018</td><td>2020</td><td>2022</td><td>2022</td><td>2024</td></tr><tr><td>代表卡</td><td>Tesla P40、GeForce GTX 1080</td><td>Tesla V100</td><td>Quadro RTX 6000、RTX 2080</td><td>RTX A6000（现在 GPU）、A100、RTX 3090</td><td>RTX 6000 Ada、L40、RTX 4090</td><td>H100、H200</td><td>B200、RTX 5090</td></tr></tbody></table><h1 id=sxm-与-pcie>SXM 与 PCIe</h1><p>SXM 和 PCIe 是两种不同的 GPU 接口形式，主要用于连接 GPU 和主机系统。它们在设计、性能、使用场景和支持的硬件平台上有显著区别，SXM 与 PCIe 对比如下所示：</p><table><thead><tr><th>特性</th><th>SXM</th><th>PCIe</th></tr></thead><tbody><tr><td>接口形式</td><td>专有接口，模块化设计</td><td>通用接口，标准 PCIe 插槽</td></tr><tr><td>带宽</td><td>高（支持 NVLink/NVSwitch）</td><td>受限于 PCIe 版本（如 PCIe 4.0/5.0）</td></tr><tr><td>互联性能</td><td>多 GPU 直接高速通信</td><td>多 GPU 通过 PCIe 总线通信</td></tr><tr><td>散热和功耗</td><td>高功耗，需要专用散热</td><td>功耗较低，散热设计灵活</td></tr><tr><td>使用场景</td><td>高性能计算、深度学习训练、数据中心</td><td>消费级、工作站、小型服务器</td></tr><tr><td>硬件兼容性</td><td>需要专用服务器（如 DGX/HGX）</td><td>兼容大多数 PCIe 主板</td></tr><tr><td>价格</td><td>较高</td><td>相对较低</td></tr><tr><td>典型 GPU 型号</td><td>A100 SXM4、H100 SXM5、V100 SXM2</td><td>A100 PCIe、RTX 4090、RTX A6000</td></tr></tbody></table><p>选择建议：</p><ul><li>选择 SXM：<ul><li>如果需要极致的性能，并且预算充足，可以选择 SXM 接口的 GPU 和专用服务器（如 DGX）；</li><li>适合大型企业、研究机构或数据中心；</li></ul></li><li>选择 PCIe：<ul><li>如果需要灵活的硬件配置、较低的预算，或者主要用于推理、小型训练任务，可以选择 PCIe 接口的 GPU；</li><li>适合中小型企业、个人开发者或 DIY 用户；</li></ul></li></ul><h1 id=deepseek-r1-资源需求示例>DeepSeek R1 资源需求示例</h1><p>以下方式列举了 DeepSeek R1 推理的硬件配置方案，仅供参考，具体配置需根据实际需求和预算进行调整。</p><table><thead><tr><th>方案</th><th>建议</th><th>概述</th><th>优点</th><th>缺点</th><th>总显存</th><th>电源</th><th>价格</th></tr></thead><tbody><tr><td>双机 A100/A800 PCIe</td><td>不推荐</td><td>自行购买10卡服务器两台，再单独购买 20 块 A100（甚至感觉都不够）</td><td>1. 没有 fp8 计算单元，最近抛货比较多，价格有所降低；<br>2. 购买渠道比较灵活方便</td><td>1. Ampere 这代显卡没有 fp8 计算单元，如果跑不量化的版本，只能跑 scale 上去的 bf16，模型本身占用的显存就要翻倍（大概 1.4T），剩余给上下文和并发的 KV Cache 没多少；<br>2. 卡已禁售，买到的原则上都是二手，只能依靠经销商保修；<br>3. A100 架构放现在算比较老的了，两台纯粹是堆显存，就这可能还不太够</td><td>80G x 20 = 1600GB</td><td>约 10 kW</td><td>200w 左右</td></tr><tr><td>单台 DGX H200</td><td>最推荐</td><td>能买到的最新最快的 Nvidia 官方平台</td><td>1. 有原生 fp8 计算单元，比 A100 架构更新，推理速度快；<br>2. 单机，不需要考虑双机互联的带宽瓶颈问题；<br>3. Nvidia 整机方案可靠性比较好</td><td>1. 货少，价格不透明，可能比较贵；<br>2. 显卡使用专有接口连接至主板，非 PCIe 接口，不好升级和更换；<br>3. 一体化程度比较高，又是走私产品，一旦发生意外硬件损坏感觉会比较难修</td><td>141G x 8 = 1128GB</td><td>约 8 kW</td><td>285w 左右</td></tr><tr><td>单机8卡 H200 SXM</td><td>最推荐</td><td>最适中的方案</td><td>1. 周边配置可以选低一点，价格会比 DGX H200 便宜；<br>2. 单机，不需要考虑双机互联的带宽瓶颈问题</td><td>1. 卡已禁售，买到的原则上都是二手，只能依靠经销商保修</td><td>141G x 8 = 1128GB</td><td>约 8 kW</td><td>245w 左右</td></tr><tr><td>双机 H100/H800 SXM/PCIe</td><td>推荐</td><td>主流方案之一</td><td>1. 有原生 fp8 计算单元，比 A100 架构更新，推理速度快；<br>2. 购买渠道比较灵活方便</td><td>1. 卡已禁售，买到的原则上都是二手，只能依靠经销商保修</td><td>80G x 16 = 1280GB</td><td>约 10 kW</td><td>大概差不多价格</td></tr><tr><td>国行 H40 SXM 双机</td><td>不是很推荐</td><td>好处就是全部都是正规渠道完整保修</td><td>1. 未禁售，货源可靠，有完整保修；<br>2. 好购买</td><td>1. H40 中国特供卡，而且连 Nvidia 官网都没清单；<br>2. 虽然有 fp8 计算单元，但是性能被砍很多</td><td>96G x 16 = 1536GB</td><td>-</td><td>220w 左右</td></tr><tr><td>AMD MI300x 整机</td><td>一般推荐</td><td>属于是钱足够的话我是不想用，钱不够的话不是不能用</td><td>1. 有还算比较稳定货源；<br>2. 有成功跑起来的案例和测试数据；<br>3. AMD 官方自己站台了是支持 Deepseek</td><td>1. AMD 的驱动比较草台，可能会有一些驱动导致的上游问题；<br>2. ROCm 推理 AMD 官方是推荐用 SGLang，SGLang 本身还不是非常成熟，活跃更新中，跑 Deepseek 要不可避免使用测试版本</td><td>192G x 8 = 1536GB</td><td>-</td><td>200w 左右</td></tr><tr><td>华为 910B/910C</td><td>不是很推荐</td><td>硅基流动说他们用的华为，有成功案例</td><td>-</td><td>1. 资料很少，而且华为自己就不怎么喜欢对外提供资料；<br>2. 910B 和 C 都不支持 fp8，显存占用也是很大</td><td>-</td><td>-</td><td>-</td></tr></tbody></table><h1 id=h20大坑货>H20（大坑货）</h1><p><img src=/images/2025-03-15-deepseek-r1-gpu-resource/1.png alt></p><h1 id=运行示例>运行示例</h1><ul><li><a href=https://zhuanlan.zhihu.com/p/22564788535>昇腾 910B 部署满血 DeepSeek-R1（BF16）</a> 可参考华为官网，<a href=https://www.hiascend.com/software/modelzoo/models/detail/68457b8a51324310aad9a0f55c3e56e3>DeepSeek-R1</a>。</li><li>单机 8 卡 H200 SXM 配置如下所示：
<img src=/images/2025-03-15-deepseek-r1-gpu-resource/2.png alt></li></ul><p><span style=color:red>如果跑 DeepSeek 量化模型，那另说，在此不叙述；</span></p><hr><ul class=pager><li class=previous><a href=/post/2025-03-09-llm-deepseek-r1/ data-toggle=tooltip data-placement=top title="LLM 教程（3）- 《DeepSeek R1 论文精读 - 通过强化学习推动大语言模型推理能力的突破与创新》">&larr;
Previous Post</a></li><li class=next><a href=/post/2025-03-16-llm-deepseek-r1/ data-toggle=tooltip data-placement=top title="深度剖析 DeepSeek R1 论文">Next
Post &rarr;</a></li></ul></div><div class="col-lg-2 col-lg-offset-0
visible-lg-block
sidebar-container
catalog-container"><div class=side-catalog><hr class="hidden-sm hidden-xs"><h5><a class=catalog-toggle href=#>CATALOG</a></h5><ul class=catalog-body></ul></div></div><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
sidebar-container"></div></div></div></article><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"><li><a href=mailto:tanjunchen20@gmail.com><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-envelope fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=/img/wechat.jpg><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-weixin fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://github.com/tanjunchen><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-github fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="copyright text-muted">Copyright &copy; 陈谭军 2025</p></div></div></div></footer><script>function loadAsync(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(null,e)},!1),i.parentNode.insertBefore(n,i)}</script><script>$("#tag_cloud").length!==0&&loadAsync("/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:"#bbbbee",end:"#0085a1"}},$("#tag_cloud a").tagcloud()})</script><script>loadAsync("https://cdn.jsdelivr.net/npm/fastclick@1.0.6/lib/fastclick.min.js",function(){var e=document.querySelector("nav");e&&FastClick.attach(e)})</script><script type=text/javascript>function generateCatalog(e){_containerSelector="div.post-container";var t,n,s,o,i,r=$(_containerSelector),a=r.find("h1,h2,h3,h4,h5,h6");return $(e).html(""),a.each(function(){n=$(this).prop("tagName").toLowerCase(),i="#"+$(this).prop("id"),s=$(this).text(),t=$('<a href="'+i+'" rel="nofollow">'+s+"</a>"),o=$('<li class="'+n+'_nav"></li>').append(t),$(e).append(o)}),!0}generateCatalog(".catalog-body"),$(".catalog-toggle").click(function(e){e.preventDefault(),$(".side-catalog").toggleClass("fold")}),loadAsync("/js/jquery.nav.js",function(){$(".catalog-body").onePageNav({currentClass:"active",changeHash:!1,easing:"swing",filter:"",scrollSpeed:700,scrollOffset:0,scrollThreshold:.2,begin:null,end:null,scrollChange:null,padding:80})})</script></body></html>